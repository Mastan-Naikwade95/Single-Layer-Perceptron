{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.utils import shuffle \n",
    "import tensorflow as tf \n",
    "from sklearn import preprocessing \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Wine     Alcohol  Malic.acid         Ash         Acl          Mg  \\\n",
      "count  178.000000  178.000000  178.000000  178.000000  178.000000  178.000000   \n",
      "mean     1.938202   13.000618    2.336348    2.366517   19.494944   99.741573   \n",
      "std      0.775035    0.811827    1.117146    0.274344    3.339564   14.282484   \n",
      "min      1.000000   11.030000    0.740000    1.360000   10.600000   70.000000   \n",
      "25%      1.000000   12.362500    1.602500    2.210000   17.200000   88.000000   \n",
      "50%      2.000000   13.050000    1.865000    2.360000   19.500000   98.000000   \n",
      "75%      3.000000   13.677500    3.082500    2.557500   21.500000  107.000000   \n",
      "max      3.000000   14.830000    5.800000    3.230000   30.000000  162.000000   \n",
      "\n",
      "          Phenols  Flavanoids  Nonflavanoid.phenols     Proanth   Color.int  \\\n",
      "count  178.000000  178.000000            178.000000  178.000000  178.000000   \n",
      "mean     2.295112    2.029270              0.361854    1.590899    5.058090   \n",
      "std      0.625851    0.998859              0.124453    0.572359    2.318286   \n",
      "min      0.980000    0.340000              0.130000    0.410000    1.280000   \n",
      "25%      1.742500    1.205000              0.270000    1.250000    3.220000   \n",
      "50%      2.355000    2.135000              0.340000    1.555000    4.690000   \n",
      "75%      2.800000    2.875000              0.437500    1.950000    6.200000   \n",
      "max      3.880000    5.080000              0.660000    3.580000   13.000000   \n",
      "\n",
      "              Hue          OD      Proline  \n",
      "count  178.000000  178.000000   178.000000  \n",
      "mean     0.957449    2.611685   746.893258  \n",
      "std      0.228572    0.709990   314.907474  \n",
      "min      0.480000    1.270000   278.000000  \n",
      "25%      0.782500    1.937500   500.500000  \n",
      "50%      0.965000    2.780000   673.500000  \n",
      "75%      1.120000    3.170000   985.000000  \n",
      "max      1.710000    4.000000  1680.000000  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"wine.csv\", header=0) \n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wine</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic.acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Acl</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid.phenols</th>\n",
       "      <th>Proanth</th>\n",
       "      <th>Color.int</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wine  Alcohol  Malic.acid   Ash   Acl   Mg  Phenols  Flavanoids  \\\n",
       "0     1    14.23        1.71  2.43  15.6  127     2.80        3.06   \n",
       "1     1    13.20        1.78  2.14  11.2  100     2.65        2.76   \n",
       "2     1    13.16        2.36  2.67  18.6  101     2.80        3.24   \n",
       "3     1    14.37        1.95  2.50  16.8  113     3.85        3.49   \n",
       "4     1    13.24        2.59  2.87  21.0  118     2.80        2.69   \n",
       "\n",
       "   Nonflavanoid.phenols  Proanth  Color.int   Hue    OD  Proline  \n",
       "0                  0.28     2.29       5.64  1.04  3.92     1065  \n",
       "1                  0.26     1.28       4.38  1.05  3.40     1050  \n",
       "2                  0.30     2.81       5.68  1.03  3.17     1185  \n",
       "3                  0.24     2.18       7.80  0.86  3.45     1480  \n",
       "4                  0.39     1.82       4.32  1.04  2.93      735  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[1:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = df.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wine</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic.acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Acl</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid.phenols</th>\n",
       "      <th>Proanth</th>\n",
       "      <th>Color.int</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14.20</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "      <td>112</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>3</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>3</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>3</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>3</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>3</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Wine  Alcohol  Malic.acid   Ash   Acl   Mg  Phenols  Flavanoids  \\\n",
       "1       1    13.20        1.78  2.14  11.2  100     2.65        2.76   \n",
       "2       1    13.16        2.36  2.67  18.6  101     2.80        3.24   \n",
       "3       1    14.37        1.95  2.50  16.8  113     3.85        3.49   \n",
       "4       1    13.24        2.59  2.87  21.0  118     2.80        2.69   \n",
       "5       1    14.20        1.76  2.45  15.2  112     3.27        3.39   \n",
       "..    ...      ...         ...   ...   ...  ...      ...         ...   \n",
       "173     3    13.71        5.65  2.45  20.5   95     1.68        0.61   \n",
       "174     3    13.40        3.91  2.48  23.0  102     1.80        0.75   \n",
       "175     3    13.27        4.28  2.26  20.0  120     1.59        0.69   \n",
       "176     3    13.17        2.59  2.37  20.0  120     1.65        0.68   \n",
       "177     3    14.13        4.10  2.74  24.5   96     2.05        0.76   \n",
       "\n",
       "     Nonflavanoid.phenols  Proanth  Color.int   Hue    OD  Proline  \n",
       "1                    0.26     1.28       4.38  1.05  3.40     1050  \n",
       "2                    0.30     2.81       5.68  1.03  3.17     1185  \n",
       "3                    0.24     2.18       7.80  0.86  3.45     1480  \n",
       "4                    0.39     1.82       4.32  1.04  2.93      735  \n",
       "5                    0.34     1.97       6.75  1.05  2.85     1450  \n",
       "..                    ...      ...        ...   ...   ...      ...  \n",
       "173                  0.52     1.06       7.70  0.64  1.74      740  \n",
       "174                  0.43     1.41       7.30  0.70  1.56      750  \n",
       "175                  0.43     1.35      10.20  0.59  1.56      835  \n",
       "176                  0.53     1.46       9.30  0.60  1.62      840  \n",
       "177                  0.56     1.35       9.20  0.61  1.60      560  \n",
       "\n",
       "[177 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "        1.065e+03],\n",
       "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "        1.050e+03],\n",
       "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "        1.185e+03],\n",
       "       ...,\n",
       "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "        8.350e+02],\n",
       "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "        8.400e+02],\n",
       "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "        5.600e+02]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "        1.065e+03],\n",
       "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "        1.050e+03],\n",
       "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "        1.185e+03],\n",
       "       ...,\n",
       "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "        8.350e+02],\n",
       "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "        8.400e+02],\n",
       "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "        5.600e+02]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Wine'].values-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = tf.one_hot(indices = y, depth=3, on_value = 1., off_value = 0., axis = 1 ,name = \"a\").eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = shuffle (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler() \n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y =shuffle (X, Y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr=X[0:140,:]\n",
    "Ytr=Y[0:140,:]\n",
    "Xt=X[140:178,:]\n",
    "Yt=Y[140:178,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Ytr = shuffle (Xtr, Ytr, random_state=0) \n",
    "batch_xs, batch_ys = Xtr , Ytr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_history = np.empty(shape=[1],dtype=float) \n",
    "training_epochs = 100\n",
    "learning_rate = 0.1\n",
    "n_dim = X.shape[1]\n",
    "n_class = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the number of hidden layers and number of neurons for each layer\n",
    "n_hidden_1 = 60\n",
    "n_hidden_2 = 60\n",
    "n_hidden_3 = 60\n",
    "n_hidden_4 = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= tf.placeholder(tf.float32, [None, 13]) \n",
    "W= tf.Variable(tf.zeros([13, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= tf.Variable(tf.zeros([3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activationsd\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.sigmoid(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.sigmoid(layer_2)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.sigmoid(layer_3)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_4 = tf.add(tf.matmul(layer_3, weights['h4']), biases['b4'])\n",
    "    layer_4 = tf.nn.relu(layer_4)\n",
    "\n",
    "    # Output layer with linear activation\n",
    "\n",
    "    out_layer = tf.matmul(layer_4, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the weights and the biases for each layer\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.truncated_normal([n_dim, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3])),\n",
    "    'h4': tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_4, n_class]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4': tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_class]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-26-759fa692ea0a>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Call your model defined\n",
    "y = multilayer_perceptron(x, weights, biases)\n",
    "#define the cost function and optimizer\n",
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0  -  cost:  28.565784  - MSE:  3323.0562 - Accuracy:  0.55263156\n",
      "epoch :  1  -  cost:  16.044685  - MSE:  1027.7006 - Accuracy:  0.23684211\n",
      "epoch :  2  -  cost:  40.20039  - MSE:  1323.573 - Accuracy:  0.39473686\n",
      "epoch :  3  -  cost:  2.3371193  - MSE:  96.87368 - Accuracy:  0.7894737\n",
      "epoch :  4  -  cost:  2.8298414  - MSE:  165.4077 - Accuracy:  0.55263156\n",
      "epoch :  5  -  cost:  2.2917745  - MSE:  104.61369 - Accuracy:  0.6052632\n",
      "epoch :  6  -  cost:  4.526582  - MSE:  168.14517 - Accuracy:  0.7368421\n",
      "epoch :  7  -  cost:  5.2234864  - MSE:  162.83907 - Accuracy:  0.55263156\n",
      "epoch :  8  -  cost:  2.4449353  - MSE:  175.49496 - Accuracy:  0.7894737\n",
      "epoch :  9  -  cost:  1.4649982  - MSE:  117.953735 - Accuracy:  0.7631579\n",
      "epoch :  10  -  cost:  0.21916525  - MSE:  98.183334 - Accuracy:  0.9736842\n",
      "epoch :  11  -  cost:  0.18010305  - MSE:  98.1006 - Accuracy:  0.9736842\n",
      "epoch :  12  -  cost:  0.1476405  - MSE:  97.39591 - Accuracy:  0.9736842\n",
      "epoch :  13  -  cost:  0.12018242  - MSE:  96.39362 - Accuracy:  0.9736842\n",
      "epoch :  14  -  cost:  0.09708774  - MSE:  95.633835 - Accuracy:  0.9736842\n",
      "epoch :  15  -  cost:  0.07821548  - MSE:  95.1553 - Accuracy:  0.9736842\n",
      "epoch :  16  -  cost:  0.063083224  - MSE:  94.82687 - Accuracy:  0.9736842\n",
      "epoch :  17  -  cost:  0.04987582  - MSE:  94.435684 - Accuracy:  0.9736842\n",
      "epoch :  18  -  cost:  0.040750686  - MSE:  94.33605 - Accuracy:  0.9736842\n",
      "epoch :  19  -  cost:  0.03462882  - MSE:  94.229935 - Accuracy:  0.9736842\n",
      "epoch :  20  -  cost:  0.02994615  - MSE:  94.30872 - Accuracy:  0.9736842\n",
      "epoch :  21  -  cost:  0.025968032  - MSE:  94.26411 - Accuracy:  0.9736842\n",
      "epoch :  22  -  cost:  0.022868916  - MSE:  94.40368 - Accuracy:  0.9736842\n",
      "epoch :  23  -  cost:  0.020259775  - MSE:  94.41321 - Accuracy:  0.9736842\n",
      "epoch :  24  -  cost:  0.018175095  - MSE:  94.55474 - Accuracy:  0.9736842\n",
      "epoch :  25  -  cost:  0.016405417  - MSE:  94.5957 - Accuracy:  0.9736842\n",
      "epoch :  26  -  cost:  0.014927868  - MSE:  94.73928 - Accuracy:  0.9736842\n",
      "epoch :  27  -  cost:  0.013677517  - MSE:  94.814705 - Accuracy:  0.9736842\n",
      "epoch :  28  -  cost:  0.012612815  - MSE:  94.94036 - Accuracy:  0.9736842\n",
      "epoch :  29  -  cost:  0.011709486  - MSE:  95.018196 - Accuracy:  0.9736842\n",
      "epoch :  30  -  cost:  0.010915816  - MSE:  95.13118 - Accuracy:  0.9736842\n",
      "epoch :  31  -  cost:  0.010246108  - MSE:  95.20191 - Accuracy:  0.9736842\n",
      "epoch :  32  -  cost:  0.009636955  - MSE:  95.30164 - Accuracy:  0.9736842\n",
      "epoch :  33  -  cost:  0.009118641  - MSE:  95.37012 - Accuracy:  0.9736842\n",
      "epoch :  34  -  cost:  0.008637347  - MSE:  95.46421 - Accuracy:  0.9736842\n",
      "epoch :  35  -  cost:  0.008222561  - MSE:  95.55316 - Accuracy:  0.9736842\n",
      "epoch :  36  -  cost:  0.007835314  - MSE:  95.61662 - Accuracy:  0.9736842\n",
      "epoch :  37  -  cost:  0.0074993824  - MSE:  95.70766 - Accuracy:  0.9736842\n",
      "epoch :  38  -  cost:  0.0071816547  - MSE:  95.77419 - Accuracy:  0.9736842\n",
      "epoch :  39  -  cost:  0.0069027245  - MSE:  95.86083 - Accuracy:  0.94736844\n",
      "epoch :  40  -  cost:  0.006636924  - MSE:  95.92538 - Accuracy:  0.94736844\n",
      "epoch :  41  -  cost:  0.0064011835  - MSE:  95.99316 - Accuracy:  0.94736844\n",
      "epoch :  42  -  cost:  0.0061763856  - MSE:  96.06482 - Accuracy:  0.94736844\n",
      "epoch :  43  -  cost:  0.005973896  - MSE:  96.13142 - Accuracy:  0.94736844\n",
      "epoch :  44  -  cost:  0.0057814345  - MSE:  96.21048 - Accuracy:  0.94736844\n",
      "epoch :  45  -  cost:  0.005605852  - MSE:  96.26392 - Accuracy:  0.94736844\n",
      "epoch :  46  -  cost:  0.0054396302  - MSE:  96.341255 - Accuracy:  0.94736844\n",
      "epoch :  47  -  cost:  0.0052857124  - MSE:  96.40184 - Accuracy:  0.94736844\n",
      "epoch :  48  -  cost:  0.005141092  - MSE:  96.46531 - Accuracy:  0.94736844\n",
      "epoch :  49  -  cost:  0.005004516  - MSE:  96.52475 - Accuracy:  0.94736844\n",
      "epoch :  50  -  cost:  0.0048779743  - MSE:  96.58658 - Accuracy:  0.94736844\n",
      "epoch :  51  -  cost:  0.004756152  - MSE:  96.64465 - Accuracy:  0.94736844\n",
      "epoch :  52  -  cost:  0.0046438593  - MSE:  96.69454 - Accuracy:  0.94736844\n",
      "epoch :  53  -  cost:  0.004535624  - MSE:  96.75501 - Accuracy:  0.94736844\n",
      "epoch :  54  -  cost:  0.004433912  - MSE:  96.81216 - Accuracy:  0.94736844\n",
      "epoch :  55  -  cost:  0.0043377113  - MSE:  96.87002 - Accuracy:  0.94736844\n",
      "epoch :  56  -  cost:  0.004245106  - MSE:  96.92516 - Accuracy:  0.94736844\n",
      "epoch :  57  -  cost:  0.004159125  - MSE:  96.972435 - Accuracy:  0.94736844\n",
      "epoch :  58  -  cost:  0.004075319  - MSE:  97.028725 - Accuracy:  0.94736844\n",
      "epoch :  59  -  cost:  0.0039962097  - MSE:  97.08272 - Accuracy:  0.94736844\n",
      "epoch :  60  -  cost:  0.003920934  - MSE:  97.13683 - Accuracy:  0.94736844\n",
      "epoch :  61  -  cost:  0.00384803  - MSE:  97.182144 - Accuracy:  0.94736844\n",
      "epoch :  62  -  cost:  0.0037795685  - MSE:  97.23466 - Accuracy:  0.94736844\n",
      "epoch :  63  -  cost:  0.0037131344  - MSE:  97.28685 - Accuracy:  0.94736844\n",
      "epoch :  64  -  cost:  0.0036491368  - MSE:  97.33078 - Accuracy:  0.94736844\n",
      "epoch :  65  -  cost:  0.003589046  - MSE:  97.375145 - Accuracy:  0.94736844\n",
      "epoch :  66  -  cost:  0.0035301384  - MSE:  97.433075 - Accuracy:  0.94736844\n",
      "epoch :  67  -  cost:  0.0034736139  - MSE:  97.475555 - Accuracy:  0.94736844\n",
      "epoch :  68  -  cost:  0.003420035  - MSE:  97.525314 - Accuracy:  0.94736844\n",
      "epoch :  69  -  cost:  0.0033675074  - MSE:  97.567375 - Accuracy:  0.94736844\n",
      "epoch :  70  -  cost:  0.0033170818  - MSE:  97.609604 - Accuracy:  0.94736844\n",
      "epoch :  71  -  cost:  0.0032691834  - MSE:  97.65825 - Accuracy:  0.94736844\n",
      "epoch :  72  -  cost:  0.0032220697  - MSE:  97.7056 - Accuracy:  0.94736844\n",
      "epoch :  73  -  cost:  0.0031766656  - MSE:  97.74623 - Accuracy:  0.94736844\n",
      "epoch :  74  -  cost:  0.0031334863  - MSE:  97.79303 - Accuracy:  0.94736844\n",
      "epoch :  75  -  cost:  0.0030909926  - MSE:  97.83309 - Accuracy:  0.94736844\n",
      "epoch :  76  -  cost:  0.0030498866  - MSE:  97.873314 - Accuracy:  0.94736844\n",
      "epoch :  77  -  cost:  0.0030106655  - MSE:  97.91356 - Accuracy:  0.94736844\n",
      "epoch :  78  -  cost:  0.0029722168  - MSE:  97.959145 - Accuracy:  0.94736844\n",
      "epoch :  79  -  cost:  0.0029348475  - MSE:  97.99847 - Accuracy:  0.94736844\n",
      "epoch :  80  -  cost:  0.0028988859  - MSE:  98.043236 - Accuracy:  0.94736844\n",
      "epoch :  81  -  cost:  0.0028639918  - MSE:  98.086975 - Accuracy:  0.94736844\n",
      "epoch :  82  -  cost:  0.0028298106  - MSE:  98.12488 - Accuracy:  0.94736844\n",
      "epoch :  83  -  cost:  0.0027966262  - MSE:  98.16292 - Accuracy:  0.94736844\n",
      "epoch :  84  -  cost:  0.0027648401  - MSE:  98.20094 - Accuracy:  0.94736844\n",
      "epoch :  85  -  cost:  0.0027334972  - MSE:  98.243744 - Accuracy:  0.94736844\n",
      "epoch :  86  -  cost:  0.0027030315  - MSE:  98.28082 - Accuracy:  0.94736844\n",
      "epoch :  87  -  cost:  0.00267354  - MSE:  98.31759 - Accuracy:  0.94736844\n",
      "epoch :  88  -  cost:  0.002644968  - MSE:  98.35895 - Accuracy:  0.94736844\n",
      "epoch :  89  -  cost:  0.0026168372  - MSE:  98.39496 - Accuracy:  0.94736844\n",
      "epoch :  90  -  cost:  0.0025894255  - MSE:  98.43094 - Accuracy:  0.94736844\n",
      "epoch :  91  -  cost:  0.0025628917  - MSE:  98.46685 - Accuracy:  0.94736844\n",
      "epoch :  92  -  cost:  0.0025370053  - MSE:  98.507095 - Accuracy:  0.94736844\n",
      "epoch :  93  -  cost:  0.002511567  - MSE:  98.54228 - Accuracy:  0.94736844\n",
      "epoch :  94  -  cost:  0.0024867414  - MSE:  98.57737 - Accuracy:  0.94736844\n",
      "epoch :  95  -  cost:  0.0024626034  - MSE:  98.61237 - Accuracy:  0.94736844\n",
      "epoch :  96  -  cost:  0.0024379892  - MSE:  98.65352 - Accuracy:  0.94736844\n",
      "epoch :  97  -  cost:  0.0024138892  - MSE:  98.68945 - Accuracy:  0.94736844\n",
      "epoch :  98  -  cost:  0.002390355  - MSE:  98.725006 - Accuracy:  0.94736844\n",
      "epoch :  99  -  cost:  0.0023673626  - MSE:  98.76023 - Accuracy:  0.94736844\n"
     ]
    }
   ],
   "source": [
    "#calculate the cost and the accuracy for each epoch\n",
    "mse_history = []\n",
    "accuracy_history =[]\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    cost = sess.run(cost_function, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    cost_history = np.append(cost_history, cost)\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    #print(\"Accuracy: \", (sess.run(accuracy, feed_dict={x: test_x, y_: test_y})))\n",
    "    pred_y = sess.run(y, feed_dict={x: Xt})\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - Yt))\n",
    "    mse_ = sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy = (sess.run(accuracy, feed_dict={x: Xt, y_: Yt}))\n",
    "    accuracy_history.append(accuracy)\n",
    "\n",
    "    print('epoch : ', epoch, ' - ', 'cost: ', cost, \" - MSE: \", mse_, \"- Accuracy: \",accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.94736844\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy\",(sess.run(accuracy,feed_dict={x: Xt, y_: Yt})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(cost_history)),cost_history)\n",
    "plt.axis([0,training_epochs,0,np.max(cost_history)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
